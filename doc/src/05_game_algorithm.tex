% Section 5: Timed Bisimulation Game Algorithm
\section{Game-Based Checking Algorithm}
\subsection{Attacker/Defender Paradigm}
We cast refinement as a one-sided safety game. States of the game are candidate pairs in relation R. The \emph{attacker} chooses an observable transition of the refined automaton; the \emph{defender} must reply with a weak ($\tau^* a \tau^*$) transition of the abstract automaton satisfying timing side conditions.

If defender cannot match, the pair is losing and removed. Greatest fixed point of non-losing pairs constitutes the refinement relation.

\subsection{Game Graph (Implicit)}
The algorithm avoids explicit construction of the full product graph; instead it iteratively filters a hash set of pairs. Successor generation (weak $\tau^* a \tau^*$) is recomputed on demand.

\subsection{Termination}
Number of zone pairs is finite due to extrapolation. Each iteration strictly removes at least one pair or stops. Thus algorithm terminates.

\subsection{Pseudo-Code}
\begin{lstlisting}[language=C++]
R = { (z_r, z_a) | loc(z_r)=loc(z_a) }
repeat
  removed = false
  for (p in R):
     for each observable tr from p.r:
        if no matching abstract weak transition exists in p.a:
            mark p for removal; break
  remove all marked from R
until !removed
return !R.empty()
\end{lstlisting}

\subsection{Optimisation Opportunities}
\begin{itemize}
  \item Memoize $\tau$-closure and weak successors.
  \item Pre-filter abstract transitions by label/direction.
  \item Maintain reverse dependency graph (predecessors) to localise removals.
  \item Early pruning using DBM inclusion seeding (exclude impossible pairs initially).
\end{itemize}

\subsection{Implemented Optimisations}
The current code base implements the four opportunities above:
\begin{description}
  \item[Closure Cache] Map \texttt{ZoneState*} to vector of $\tau$-reachable states (function: \texttt{tau\_closure\_cached}). Avoids repeated BFS.
  \item[Weak Successor Cache] Keyed by (zone, action) (struct \texttt{WeakKey}); stores $\tau^* a \tau^*$ endpoints.
  \item[Early Pruning Seed] Initial relation only includes pairs with same location and refined zone $\subseteq$ abstract zone (DBM inclusion).
  \item[Reverse Dependencies] Map from supporting pair to dependents that relied on it to justify at least one match (\texttt{reverse\_deps\_}). When a pair is removed, only its dependents are re-validated (worklist), avoiding full rescans.
\end{description}

\paragraph{Complexity Impact.} If $C_\tau$ is average $\tau$-closure size, naive recomputation costs $O(|R|\cdot deg \cdot C_\tau)$ per iteration. Caching reduces it to amortised $O(N_\tau + N_{weak})$ where $N_\tau$ and $N_{weak}$ are number of distinct closure / weak-successor queries.

\paragraph{Memory Tradeoff.} Caches store vectors of raw pointers only; reverse dependency graph stores adjacency lists restricted to observed supporting edges, typically much smaller than full $|R|^2$ worst-case.

\subsection{Worked Example (Mini Game)}
Assume refined automaton $R$ and abstract automaton $A$ each have two locations $L0, L1$ and one observable label $a$ plus internal $\tau$. Initial zones are trivial (all clocks 0). Transitions:
\begin{center}
\begin{tabular}{l|l}
$R$ & $L0 \xrightarrow{a,\; x\le 2,\; x:=0} L1$ \\
$A$ & $L0 \xrightarrow{\tau,\; x<1} L0$, then $L0 \xrightarrow{a,\; x\le 3,\; x:=0} L1$ \\
\end{tabular}
\end{center}

Game iteration for pair $(L0,Z0),(L0,Z0)$:
\begin{enumerate}
  \item Attacker picks $a$ from $R$ (enabled for delays $d$ with $d\le 2$).
  \item Defender computes weak successors in $A$: $\tau$-closure allows any number of $\tau$ steps while $x<1$, then must delay to some $d \le 3$ for the $a$ transition. Combined pattern: delay $d_1 < 1$, zero or more times, then additional delay $d_2$ with $d_1 + d_2 \le 3$.
  \item Timing side condition: every refined enabling delay $d \le 2$ must be matchable. Choose defender decomposition with $d_1 = \min(d, 0.9)$ (staying under 1) and $d_2 = d - d_1$. Since $d \le 2$, total $d_1+d_2 = d \le 2 \le 3$ holds; guard $x\le 3$ satisfied.
  \item Defender succeeds; pair survives.
\end{enumerate}

If refined guard were $x \le 4$, delays $d\in (3,4]$ would not be matchable (abstract guard caps at 3). Pair would be removed, implying no refinement.

\paragraph{Code Path.} In C++: attacker side enumerated in \texttt{observable\_edges(refined)}. Defender calls \texttt{weak\_observable\_successors(abstract, 'a')} producing zones after $\tau^* a \tau^*$. Function \texttt{timing\_ok} reconstructs enabling DBMs and checks inclusion: refined enabling zone $\subseteq$ abstract enabling zone for action $a$. Failure triggers marking for removal.

\paragraph{Caching Impact.} If multiple pairs share the same abstract zone and label $a$, memoising the weak successors avoids recomputing the $\tau$-closure, reducing complexity from repeated closure traversals to a single stored vector of resulting zones.

\subsection{Abstract Complexity and Relation to Region Graph Checking}
We provide an abstract (parameter–oriented) complexity characterization, then relate it to classical UPPAAL-style model checking via the region graph bound.

\paragraph{Parameters.} Let $C$ be the number of clocks, $M$ the maximal constant appearing in guards/invariants, and $|Act|$ the number of observable labels. Let $Z_r, Z_a$ be the numbers of symbolic states (locations + zones after extrapolation) for the refined and abstract automata; denote $R$ the number of candidate pairs retained after initial pruning (location match + zone inclusion). Let $deg_r$ be the average number of observable outgoing transitions per refined symbolic state and $C_\tau$ the average size of an abstract $\tau$-closure (internal symbolic states reachable without consuming an observable action). We use $n = C+1$ for DBM dimension.

\paragraph{High-Level Cost Decomposition.}
\begin{itemize}[leftmargin=1.2em]
  \item Symbolic expansion (zone graph building): each new zone requires a constant number of DBM canonicalisations (closure) giving $O(n^3)$ per zone; total $O((Z_r+Z_a) n^3)$.
  \item Weak observable successor derivation ($\tau^* a \tau^*$) when first requested for an abstract zone + action: one internal BFS over at most $C_\tau$ zones, each incurring at most one closure $O(n^3)$; amortised $O(C_\tau n^3)$ per (zone, action).
  \item Pair validation: for each refined observable edge we test existence of at least one matching abstract weak successor zone and perform a timing inclusion (matrix compare) $O(n^2)$. Amortised cost $O(R\cdot deg_r \cdot n^2)$ given cached weak successors.
  \item Fixed-point removal propagation (reverse dependencies): near-linear in $R$ in practice; $O(R^2)$ pathological upper bound (dense dependency graph) rarely realised after inclusion seeding.
\end{itemize}

\paragraph{Abstract Bound.} Combining dominant terms:
\[
  T_{RTWBS} = O\Big( (Z_r+Z_a) n^3 + N_{weak}\, C_\tau n^3 + R\, deg_r\, n^2 + R^2_{worst} \Big)
\]
where $N_{weak} \le Z_a \cdot |Act|$ is the number of distinct (abstract zone, action) requests actually realised. With effective caching and pruning ($R \approx \min(Z_r,Z_a)$, sparse deps) this collapses to:
\[
  T_{RTWBS}^{practical} \approx O\Big((Z_r+Z_a) n^3 + R\, deg_r\, n^2 \Big).
\]

\paragraph{Link to Region Graph.} Classical region graph size for $C$ clocks and maximal constant $M$ is $O(M^{C} C!)$; timed reachability / TCTL model checking explores (up to) all regions and evaluates temporal fixpoints, giving exponential worst-case growth in $C$ (PSPACE / EXPTIME bounds depending on logic fragment). Zone abstraction shares the same theoretical upper bound ($Z_x \subseteq O(M^{C} C!)$), but practical zone counts are usually much smaller due to convex merging and LU-extrapolation. Our refinement algorithm adds at most a multiplicative $\min(Z_r,Z_a)$ factor (instead of $Z_r Z_a$) because location mismatch/inclusion eliminate most pairs up front. Thus, while worst-case RTWBS inherits the exponential dependence on $C$ via $Z_r, Z_a$, it avoids re-solving temporal logic fixpoints and instead performs local timing inclusion tests ($O(n^2)$) on pre-built symbolic structure.

\paragraph{Comparison to UPPAAL Property Checking.} UPPAAL-style TCTL checking must: (i) generate zone graph ($O(Z n^3)$), (ii) propagate formula annotations (additional passes over $Z$), potentially repeating explorations for nested fixpoints. In contrast, RTWBS refinement between an adapted and baseline model reuses the baseline’s symbolic zones and only constructs new refined zones ($Z_r$) plus relational filtering. If an adaptation is local (adds $\Delta Z_r$ zones), cost is reduced to:
\[
  O\big( \Delta Z_r n^3 + \Delta R \cdot deg_r n^2 \big)
\]
with cached abstract closures untouched. This incremental polynomial overhead replaces a potential re-run of full property checking over $Z_a + \Delta Z_r$ zones.

\paragraph{Intuition.} Region-graph complexity stems from global enumeration of time-distinguished states. RTWBS leverages already abstracted timing structure, paying the exponential (in $C$) factor only once per distinct zone discovered, then performing purely polynomial matching on top. Hence refinement scales as a \emph{structured differential} analysis rather than full re-verification.

\paragraph{Key Contrast.}
\begin{center}
\begin{tabular}{l|l|l}
Aspect & Property (Region/Zone) Checking & RTWBS Refinement \\\hline
Global fixpoints & Yes (logic evaluation) & No (greatest simulation via deletions) \\
State construction & All of single model & Two graphs; reuse baseline \\
Extra combinatorics & Formula nesting & Pair filtering (pruned) \\
Per-step heavy op & Closure + formula ops & Closure (once) + inclusion $O(n^2)$ \\
Incremental update & Hard (re-check formula) & Local ($\Delta Z_r$, $\Delta R$) \\
Cross-product blow-up & Not applicable & Mitigated by seeding ($R \ll Z_r Z_a$) \\
Exponential source & Regions ($M^{C} C!$) & Same (via $Z_r,Z_a$) only once \\
\end{tabular}
\end{center}

\paragraph{Summary.} Refinement inherits the inherent exponential dependence on number of clocks from region/zone techniques, but (i) replaces logic fixpoint evaluation by local inclusion checks, (ii) capitalises on relation seeding to avoid full cross products, and (iii) supports incremental adaptation with cost proportional to changed symbolic structure rather than entire model size.

